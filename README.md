# Signify ğŸ”ŠğŸ¤Ÿ  
**Real-Time Speech to Sign Language Translator using Transformer-Based Models**

---

## ğŸ“Œ Description

**Signify** is a Flask-based web application that enables real-time translation of spoken English into Indian Sign Language (ISL) gestures. Built using **transformer-based models** like **Wav2Vec 2.0** (for speech recognition) and **Vision Transformer (ViT)** (for sign rendering), Signify aims to bridge the communication gap for the hearing-impaired community.

---

## ğŸ§  Features

- ğŸ¤ Speech-to-text conversion using **Wav2Vec 2.0** (with Whisper fallback)
- ğŸ¤– Text-to-sign conversion using static sign gesture images
- ğŸ“· Vision Transformer integration for future gesture recognition
- âš¡ Real-time, low-latency performance
- ğŸŒ Intuitive UI with modern design and contributor credits

---

## ğŸ“ Project Structure

Signify/
â”œâ”€â”€ app.py # Flask backend
â”œâ”€â”€ static/
â”‚ â”œâ”€â”€ Sign_images/ # Sign language images (A-Z)
â”‚ â”œâ”€â”€ css/
â”‚ â”‚ â””â”€â”€ styles.css # Styling file
â”‚ â””â”€â”€ images/ # Logo and background images
â”œâ”€â”€ templates/
â”‚ â”œâ”€â”€ index.html # Main translation page
â”‚ â”œâ”€â”€ about.html # About page
â”‚ â””â”€â”€ welcome.html # Welcome splash screen
â”œâ”€â”€ uploads/ # Temporary folder for audio
â”œâ”€â”€ requirements.txt # Required Python libraries
â””â”€â”€ README.md # This file

yaml
Copy
Edit

---

## ğŸ› ï¸ Installation

### ğŸ”¸ Prerequisites

- Python â‰¥ 3.8
- `pip` installed
- Git

---

### ğŸ”¸ Clone Repository

```bash
git clone https://github.com/yourusername/Signify.git
cd Signify
ğŸ”¸ Create Virtual Environment (Recommended)
bash
Copy
Edit
python -m venv venv
source venv/bin/activate        # On Windows: venv\Scripts\activate
ğŸ”¸ Install Requirements
bash
Copy
Edit
pip install -r requirements.txt
Required libraries include:
Flask, SpeechRecognition, transformers, pyaudio, torch, librosa, soundfile, scikit-learn, etc.

ğŸš€ Running the Application
ğŸ–¥ï¸ Run Flask App
bash
Copy
Edit
python app.py
Visit http://127.0.0.1:5000 in your browser.

ğŸ§ª How to Use
Launch the app.

Youâ€™ll see a splash screen â†’ then About â†’ then Speak Interface.

Click the ğŸ¤ button to start speaking.

Your speech will be converted to text using Wav2Vec 2.0.

The text is broken into characters, each rendered as sign language gestures.

Images corresponding to each character appear on the screen in real-time.

ğŸ“‚ Notes
Ensure your microphone is enabled and accessible via the browser.

Add your Sign_images (A-Z) in static/Sign_images/ folder.

The logo image and background should be added under static/images/.

âœï¸ Contributors
Kasi Viswanathan K, Student, SRMIST

Elatchuman RV, Student, SRMIST

Karthikeyan M, Assistant Professor, SRMIST

Sandhia GK, Associate Professor, SRMIST

ğŸ“œ License
This project is developed for academic and research purposes.

ğŸ’¡ Future Scope
Add dynamic gesture animations using ViT + video sequences

Integrate multi-lingual support using Whisper

Build Android version using Flutter

Use ViT for dynamic video gesture generation from text

yaml
Copy
Edit
